---
title: "INFO550, Week Three"
subtitle: "Manipulating and Summarizing Data with dplyr"
author: "Alex Edwards"
date: "January 29, 2020<br>Updated: `r gsub(' 0', ' ', format(Sys.Date(), format='%b %d, %Y'))`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE, purl=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(comment = "##")
library(ggplot2)
devtools::install_github("gadenbuie/xaringanthemer")
```

```{r xaringan-themer, include = FALSE, purl=FALSE}
library(xaringanthemer)

```

## Courtsey Of Chuck Lanfear at The University of Washington

---

# Death to Spreadsheets

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 90)
```

Today we'll talk more about `dplyr`: a package that does in R just about any calculation you've tried to do in Excel, but more *transparently*, *reproducibly*, and *safely*. 

Don't be the next sad research assistant who makes headlines with an Excel error ([Reinhart & Rogoff, 2010](http://www.bloomberg.com/news/articles/2013-04-18/faq-reinhart-rogoff-and-the-excel-error-that-changed-history))

---
class: inverse

# Modifying Data Frames with `dplyr`


---
# But First, Pipes (%>%)

`dplyr` uses the [`magrittr`](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html) forward pipe operator, usually called simply a **pipe**. We write pipes like `%>%` (`Ctrl+Shift+M`).

--

Pipes take the object on the *left* and apply the function on the *right*: `x %>% f(y) = f(x, y)`. Read out loud: "and then..."

--

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(gapminder)
gapminder %>% filter(country == "Canada") %>% head(2)
```

--

Pipes save us typing, make code readable, and allow chaining like above, so we use them *all the time* when manipulating data frames.

---

# Using Pipes


Pipes are clearer to read when you have each function on a separate line (inconsistent in these slides because of space constraints).

--

```{r, eval=FALSE}
take_these_data %>%
    do_first_thing(with = this_value) %>%
    do_next_thing(using = that_value) %>% ...
```

--

Stuff to the left of the pipe is passed to the *first argument* of the function on the right. Other arguments go on the right in the function. 

--

If you ever find yourself piping a function where data are not the first argument, use `.` in the data argument instead.
```{r, eval=FALSE}
yugoslavia %>% lm(pop ~ year, data = .)
```

---
# Pipe Assignment

When creating a new object from the output of piped functions, place the assignment operator at the beginning.

```{r, eval=FALSE}
lm_pop_year <- gapminder %>% 
  filter(continent == "Americas") %>%
  lm(pop ~ year, data = .)
```

No matter how long the chain of functions is, assignment is always done at the top.<sup>1</sup>

.footnote[[1] Note this is just a stylistic convention: If you prefer, you *can* do assignment at the end of the chain.]

---
# Filtering Rows (subsetting)

Recall last week we used the `filter()` command to subset data like so:
```{r}
Canada <- gapminder %>%
    filter(country == "Canada")
```

Excel analogue: Filter!

![Excel's filter](https://www.jquery-az.com/wp-content/uploads/2019/06/49-excel-filter-demo.gif)

---
# Another Operator: `%in%`

Common use case: Filter rows to things in some *set*.

We can use `%in%` like `==` but for matching *any element* in the vector on its right<sup>1</sup>. 

```{r}
former_yugoslavia <- c("Bosnia and Herzegovina", "Croatia", 
              "Macedonia", "Montenegro", "Serbia", "Slovenia")
yugoslavia <- gapminder %>% filter(country %in% former_yugoslavia)
tail(yugoslavia, 2)
```

.footnote[[1] The `c()` function is how we make **vectors** in R, which are an important data type.]

---
## `distinct()`

You can see all the *unique values* in your data for combinations of columns using `distinct()`:

```{r}
gapminder %>% distinct(continent, year)
```

---
### `distinct()` drops unused variables!


Note that the default behavior of `distinct()` is to drop all unspecified columns. If you want to get distinct rows by certain variables without dropping the others, use `distinct(.keep_all=TRUE)`:

```{r}
gapminder %>% distinct(continent, year, .keep_all=TRUE)
```

---
# Sampling Rows: `sample_n()`

We can also filter *at random* to work with a smaller dataset using `sample_n()` or `sample_frac()`.

```{r}
set.seed(413) # makes random numbers repeatable #<<
yugoslavia %>% sample_n(size = 6, replace = FALSE)
```

.footnote[Use `set.seed()` to make all random numbers in a file come up *exactly the same* each time it is run. Read *Details* in `?set.seed` if you like your brain to hurt.]

---
## Sorting: `arrange()`

Along with filtering the data to see certain rows, we might want to sort it:

```{r}
yugoslavia %>% arrange(year, desc(pop))
```

The data are sorted by ascending `year` and descending `pop`.

---
## Keeping Columns: `select()`

Not only can we limit rows, but we can include specific columns (and put them in the order listed) using `select()`. 

```{r}
yugoslavia %>% select(country, year, pop) %>% head(4)
```

---
## Dropping Columns: `select()`


We can instead drop only specific columns with `select()` using `-` signs:

```{r}
yugoslavia %>% select(-continent, -pop, -lifeExp) %>% head(4)
```

---
## Helper Functions for `select()`


`select()` has a variety of helper functions like `starts_with()`, `ends_with()`, and `contains()`, or can be given a range of continguous columns `startvar:endvar`. See `?select` for details.

These are very useful if you have a "wide" data frame with column names following a pattern or ordering. 

![DYS Data Example](http://clanfear.github.io/CSSS508/Lectures/Week3/img/dys_vars.PNG)

```{r, eval=FALSE}
DYS %>% select(starts_with("married"))
DYS %>% select(ends_with("18"))
```

---
## Renaming Columns with `select()`


We can rename columns using `select()`, but that drops everything that isn't mentioned:

```{r}
yugoslavia %>%
    select(Life_Expectancy = lifeExp) %>%
    head(4)
```

---
### Safer: Rename Columns with `rename()`


`rename()` renames variables using the same syntax as `select()` without dropping unmentioned variables.

```{r}
yugoslavia %>%
    select(country, year, lifeExp) %>%
    rename(Life_Expectancy = lifeExp) %>%
    head(4)
```

---
## Column Naming Practices

* *Good* column names will be self-describing. Don't use inscrutable abbreviations to save typing. RStudio's autocompleting functions take away the pain of long variable names: Hit `TAB` while writing code to autocomplete.

--

* *Valid* "naked" column names can contain upper or lowercase letters, numbers, periods, and underscores. They must start with a letter or period and not be a special reserved word (e.g. `TRUE`, `if`).

--

* Names are case-sensitive: `Year` and `year` are not the same thing!

--

* You can include spaces or use reserved words if you put backticks around the name. Spaces can be worth including when preparing data for `ggplot2` or `pander` since you don't have to rename axes or table headings.

---

## Column Name with Space Example

```{r}
library(pander)
yugoslavia %>% filter(country == "Serbia") %>%
    select(year, lifeExp) %>%
    rename(Year = year, `Life Expectancy` = lifeExp) %>%
    head(5) %>%
    pander(style = "rmarkdown", caption = "Serbian life expectancy")
```

---
## Create New Columns: `mutate()`

In `dplyr`, you can add new columns to a data frame using `mutate()`.

--


```{r}
yugoslavia %>% filter(country == "Serbia") %>%
    select(year, pop, lifeExp) %>%
    mutate(pop_million = pop / 1000000,
           life_exp_past_40 = lifeExp - 40) %>%
    head(5)
```

Note you can create multiple variables in a single `mutate()` call by separating the expressions with commas.

---
# `ifelse()`


A common function used in `mutate()` (and in general in R programming) is `ifelse()`. It returns a vector of values depending on a logical test.

```{r, eval=FALSE}
ifelse(test = x==y, yes = first_value , no = second_value)
```

Output from `ifelse()` if `x==y` is...
* `TRUE`: `first_value` - the value for `yes =`

* `FALSE`: `second_value` - the value for `no = `

* `NA`: `NA` - because you can't test for NA with an equality!

--

For example:

```{r}
example <- c(1, 0, NA, -2)
ifelse(example > 0, "Positive", "Not Positive")
```

---
# `ifelse()` Example


```{r}
yugoslavia %>% mutate(short_country = 
                 ifelse(country == "Bosnia and Herzegovina", 
                        "B and H", as.character(country))) %>%
    select(short_country, year, pop) %>%
    arrange(year, short_country) %>%
    head(3)
```

Read this as "For each row, if country equals 'Bosnia and Herzegovina, make `short_country` equal to 'B and H', otherwise make it equal to that row's value of `country`."

This is a simple way to change some values but not others!

---
# `recode()`


`recode()` is another useful function to use inside `mutate()`. Use `recode()` to change specific values to other values, particularly with factors. You can change multiple values at the same time. Note if a value has spaces in it, you'll need to put it in backticks!

```{r}
yugoslavia %>% 
  mutate(country = recode(country, 
                        `Bosnia and Herzegovina`="B and H", #<<
                        Montenegro="M")) %>% 
  distinct(country)
```

---
# `case_when()`

`case_when()` performs multiple `ifelse()` operations at the same time. `case_when()` allows you to create a new variable with values based on multiple logical statements. This is useful for making categorical variables or variables from combinations of other variables.

.smallish[
```{r}
gapminder %>% 
  mutate(gdpPercap_ordinal = 
    case_when(
      gdpPercap <  700 ~ "low",
      gdpPercap >= 700 & gdpPercap < 800 ~ "moderate",
      TRUE ~ "high" )) %>% # Value when all other statements are FALSE
  slice(6:9) # get rows 6 through 9
```
]

---

# `pull()`

Sometimes you want to extract a single column from a data frame as a *vector* (or single value). 

`pull()` *pulls* a column of a data frame out as a vector.

```{r}
gapminder %>% pull(lifeExp) %>% head(4)
```

```{r}
gapminder %>% select(lifeExp) %>% head(4)
```

.pull-right[.footnote[Note the difference between these two operations: The second yields only one column but is still a data frame.]]
---
class: inverse

# Summarizing with `dplyr`

---
## General Aggregation: `summarize()`

`summarize()` takes your column(s) of data and computes something using every row:

* Count how many rows there are
* Calculate the mean
* Compute the sum
* Obtain a minimum or maximum value

You can use any function in `summarize()` that aggregates multiple values into a single value (like `sd()`, `mean()`, or `max()`).

---
# `summarize()` Example

For the year 1982, let's get the number of observations, total population, mean life expectancy, and range of life expectancy for former Yugoslavian countries.

```{r}
yugoslavia %>%
    filter(year == 1982) %>%
    summarize(n_obs          = n(),
              total_pop      = sum(pop),
              mean_life_exp  = mean(lifeExp),
              range_life_exp = max(lifeExp) - min(lifeExp))
```

These new variables are calculated using *all of the rows* in `yugoslavia`

---
# Avoiding Repetition: 

### `summarize_at()`


Maybe you need to calculate the mean and standard deviation of a bunch of columns. With `summarize_at()`, put the variables to compute over first in `vars()` (like `select()` syntax) and put the functions to use in a `list()` after.

```{r}
yugoslavia %>%
    filter(year == 1982) %>%
    summarize_at(vars(lifeExp, pop), list(mean = mean, sd = sd))
```

You can also use `purrr` syntax (e.g. `~ mean(.)`) and it will automatically name the outputs.

---
# Avoiding Repetition

### Other functions:


There are additional `dplyr` functions similar to `summarize_at()`:

* `summarize_all()` and `mutate_all()` summarize / mutate *all* variables sent to them in the same way. For instance, getting the mean and standard deviation of an entire dataframe (using `purrr` style functions):

```{r, eval=FALSE}
dataframe %>% summarize_all(list(~mean(.), ~sd(.)))
```

* `summarize_if()` and `mutate_if()` summarize / mutate all variables that satisfy some logical condition. For instance, summarizing every numeric column in a dataframe at once:

```{r, eval=FALSE}
dataframe %>% summarize_if(is.numeric, list(~mean(.), ~sd(.)))
```

You can use all of these to avoid typing out the same code repeatedly!

---
# `group_by()`


The special function `group_by()` changes how functions operate on the data, most importantly `summarize()`.

Functions after `group_by()` are computed *within each group* as defined by variables given, rather than over all rows at once. Typically the variables you group by will be integers, factors, or characters, and not continuous real values.

Excel analogue: pivot tables

.image-50[![Pivot table](http://www.excel-easy.com/data-analysis/images/pivot-tables/two-dimensional-pivot-table.png)]

---
# `group_by()` example


```{r}
yugoslavia %>%
  group_by(year) %>% #<<
    summarize(num_countries     = n_distinct(country),
              total_pop         = sum(pop),
              total_gdp_per_cap = sum(pop*gdpPercap)/total_pop) %>%
    head(5)
```

Because we did `group_by()` with `year` then used `summarize()`, we get *one row per value of `year`*!

---
class: inverse
##Joining (Merging) Data Frames

---
## When Do We Need to Join Tables?

* Want to make columns using criteria too complicated for `ifelse()` or `case_when()`

  + We can work with small sets of variables then combine them back together.

* Combine data stored in separate data sets: e.g. UW registrar data with police stop records.

  + Often large surveys are broken into different data sets for each level (e.g. household, individual, neighborhood)

---
## Joining in Concept

We need to think about the following when we want to merge data frames `A` and `B`:

* Which *rows* are we keeping from each data frame?

* Which *columns* are we keeping from each data frame?

* Which variables determine whether rows *match*?

---
## Join Types: Visual
.image-50[![Join Diagram](https://1.bp.blogspot.com/-QhqMYOy8NVk/V-3pgGG5x6I/AAAAAAAAR2w/yU9qfzV4uWcO7GNApkZIOtdK_k4shXGrwCK4B/s640/Joins%2Bin%2Bphp.jpg)]


---
## Join Types: Rows and columns kept

There are many types of joins<sup>1</sup>...

* `A %>% left_join(B)`: keep all rows from `A`, matched with `B` wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% right_join(B)`: keep all rows from `B`, matched with `A` wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% inner_join(B)`: keep only rows from `A` and `B` that match, keep columns from both `A` and `B`

* `A %>% full_join(B)`: keep all rows from both `A` and `B`, matched wherever possible (`NA` when not), keep columns from both `A` and `B`

* `A %>% semi_join(B)`: keep rows from `A` that match rows in `B`, keep columns from only `A`

* `A %>% anti_join(B)`: keep rows from `A` that *don't* match a row in `B`, keep columns from only `A`

.pull-right[.footnote[[1] Usually `left_join()` does the job.]]

---
## Matching Criteria

We say rows should *match* because they have some columns containing the same value. We list these in a `by = ` argument to the join.

Matching Behavior:

* No `by`: Match using all variables in `A` and `B` that have identical names

--

* `by = c("var1", "var2", "var3")`: Match on identical values of `var1`, `var2`, and `var3` in both `A` and `B`

--

* `by = c("Avar1" = "Bvar1", "Avar2" = "Bvar2")`: Match identical values of `Avar1` variable in `A` to `Bvar1` variable in `B`, and `Avar2` variable in `A` to `Bvar2` variable in `B`

Note: If there are multiple matches, you'll get *one row for each possible combination* (except with `semi_join()` and `anti_join()`).

Need to get more complicated? Break it into multiple operations.

---
## `nycflights13` Data

We'll use data in the [`nycflights13` package](https://cran.r-project.org/web/packages/nycflights13/nycflights13.pdf). Install and load it:
```{r}
# install.packages("nycflights13") # Uncomment to run
library(nycflights13)
```

It includes five dataframes, some of which contain missing data (`NA`):

* `flights`: flights leaving JFK, LGA, or EWR in 2013
* `airlines`: airline abbreviations
* `airports`: airport metadata
* `planes`: airplane metadata
* `weather`: hourly weather data for JFK, LGA, and EWR

Note these are *separate data frames*, each needing to be *loaded separately*:

```{r, eval=FALSE}
data(flights)
data(airlines)
data(airports)
# and so on...
```

---
## Join Example #1

Who manufactures the planes that flew to Seattle?
```{r}
flights %>% filter(dest == "SEA") %>% select(tailnum) %>%
    left_join(planes %>% select(tailnum, manufacturer), #<<
              by = "tailnum") %>%
    count(manufacturer) %>% # Count observations by manufacturer
    arrange(desc(n)) # Arrange data descending by count
```

Note you can perform operations on the data inside functions such as `left_join()` and the *output* will be used by the function.

---
## Join Example #2

Which airlines had the most flights to Seattle from NYC?
```{r}
flights %>% filter(dest == "SEA") %>% 
    select(carrier) %>%
    left_join(airlines, by = "carrier") %>%
    group_by(name) %>% 
    tally() %>% #<<
    arrange(desc(n))
```

`tally()` is a shortcut for `summarize(n(.))`: It creates a variable `n` equal to the number of rows in each group.

---
## Join Example #3

Is there a relationship between departure delays and wind gusts?

```{r, warning=FALSE, message=FALSE, eval=FALSE}
library(ggplot2)
flights %>% 
    select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, 
           by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    # removing rows with missing values
    filter(!is.na(dep_delay) & !is.na(wind_gust)) %>% 
    ggplot(aes(x = wind_gust, y = dep_delay)) +
      geom_point() + 
      geom_smooth()
```

Because the data are the first argument for `ggplot()`, we can pipe them straight into a plot.

---
## Wind Gusts and Delays

```{r, warning=FALSE, message=FALSE, echo=FALSE, cache=FALSE, fig.height=4, dev='png', dpi=600}
flights %>% select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    # removing rows with missing values
    filter(!is.na(dep_delay) & !is.na(wind_gust)) %>%
    # Funky 1200 mph observations were dropped so I make new ones!
    mutate(wind_gust = if_else(row_number() %in% c(1,2,3), 1200, wind_gust)) %>%
    ggplot(aes(x = wind_gust, y = dep_delay)) +
      geom_point() + geom_smooth()
```

Check out those 1200 mph winds!<sup>1</sup>

.footnote[[1] These observations appear to have been fixed in the current data.]

---
## Redo After Removing Extreme Outliers, Just Trend

.small[
```{r, warning=FALSE, message=FALSE, eval=FALSE}
flights %>% 
    select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    filter(!is.na(dep_delay) & !is.na(wind_gust) & wind_gust < 250) %>% #<<
    ggplot(aes(x = wind_gust, y = dep_delay)) +
      geom_smooth() + 
      theme_bw(base_size = 16) +
      xlab("Wind gusts in departure hour (mph)") +
      ylab("Average departure delay (minutes)")
```
]

I removed `geom_point()` to focus on the mean trend produced by `geom_smooth()`.

---
## Wind Gusts and Delays: Mean Trend

```{r, warning=FALSE, message=FALSE, echo=FALSE, cache=FALSE, fig.height=4, dev='svg'}
flights %>% 
    select(origin, year, month, day, hour, dep_delay) %>%
    inner_join(weather, by = c("origin", "year", "month", "day", "hour")) %>%
    select(dep_delay, wind_gust) %>%
    filter(!is.na(dep_delay) & !is.na(wind_gust) & wind_gust < 250) %>% 
    ggplot(aes(x = wind_gust, y = dep_delay)) +
      geom_smooth() + 
      theme_bw(base_size = 16) +
      xlab("Wind gusts in departure hour (mph)") +
      ylab("Average departure delay (minutes)")
```

---
## Tinkering Suggestions

Some possible questions to investigate:

* What are the names of the most common destination airports?
* Which airlines fly from NYC to your home city?
* Is there a relationship between departure delays and precipitation?
* Use the time zone data in `airports` to convert flight arrival times to NYC local time.
    + What is the distribution of arrival times for flights leaving NYC over a 24 hour period?
    + Are especially late or early arrivals particular to some regions or airlines?

**Warning:** `flights` has `r nrow(flights)` rows, so if you do a sloppy join, you can end up with **many** matches per observation and have the data *explode* in size.

---